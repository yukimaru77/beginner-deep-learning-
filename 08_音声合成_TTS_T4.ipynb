{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGyDZVaFFk4s"
      },
      "source": [
        "# 深層学習体験会: テキスト音声合成（TTS）\n",
        "\n",
        "このノートブックでは、**TTS（Text-to-Speech）**技術を使って、テキストから音声を生成する方法を学びます。\n",
        "\n",
        "## TTSとは？\n",
        "\n",
        "TTS（Text-to-Speech）とは、テキストを読み上げる音声を自動生成する技術です。このノートブックでは、**Zonos**という高品質なTTSモデルを使用します。\n",
        "\n",
        "### Zonosの特徴\n",
        "- 多言語対応（日本語、英語など約100言語）\n",
        "- 感情表現が可能（喜び、悲しみ、怒りなど）\n",
        "- 声のクローニング（参照音声から声質を学習）\n",
        "- ピッチ（音の高さ）と速度の調整が可能\n",
        "\n",
        "### 応用例\n",
        "- オーディオブックの作成\n",
        "- ナビゲーションシステム\n",
        "- アクセシビリティツール（視覚障害者向け）\n",
        "- YouTubeのナレーション\n",
        "- ゲームキャラクターの音声\n",
        "\n",
        "## このノートブックの流れ\n",
        "1. 環境の準備とモデルの読み込み\n",
        "2. 参照音声のアップロード（オプション）\n",
        "3. テキストと感情設定\n",
        "4. 音声の生成と再生"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73hpURScFk4v"
      },
      "source": [
        "## ステップ1: 環境の準備とモデルの読み込み\n",
        "\n",
        "必要なライブラリをインストールし、Zonosモデルを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3nYPcqNFk4v",
        "outputId": "b8c3a77e-8dca-4f25-82b2-5de3c99c7357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\u001b[0m\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "espeak-ng is already the newest version (1.50+dfsg-10ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "fatal: destination path 'Zonos' already exists and is not an empty directory.\n",
            "/content/Zonos\n",
            "Obtaining file:///content/Zonos\n"
          ]
        }
      ],
      "source": [
        "# --- 環境のセットアップとモデルの読み込み ---\n",
        "\n",
        "# システムの更新とespeak-ngのインストール（音声合成エンジン）\n",
        "!apt update && apt install -y espeak-ng\n",
        "\n",
        "# ZonosのGitHubリポジトリをクローン\n",
        "!git clone https://github.com/Isi-dev/Zonos.git\n",
        "\n",
        "# Zonosディレクトリに移動\n",
        "%cd Zonos\n",
        "\n",
        "# Zonosをインストール（-e: 編集可能モードでインストール）\n",
        "!pip install -e .\n",
        "# !pip install --no-build-isolation -e .[compile] # オプション: ハイブリッドモードで実行する場合に必要\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import torch  # PyTorchフレームワーク\n",
        "import torchaudio  # 音声処理用ライブラリ\n",
        "from zonos.model import Zonos  # Zonosモデル\n",
        "from zonos.conditioning import make_cond_dict  # 条件付け用の関数\n",
        "\n",
        "# --- デバイスの確認 ---\n",
        "# CUDAが利用可能ならGPU、そうでなければCPUを使用\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"使用デバイス: {device}\")\n",
        "\n",
        "# --- モデルの読み込み ---\n",
        "print(\"モデルを読み込み中...\")\n",
        "# Hugging Faceから事前学習済みモデルをダウンロード\n",
        "model = Zonos.from_pretrained(\"Isi99999/Zonos-v0.1-transformer\", device=device)\n",
        "print(\"モデルの読み込みが完了しました！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDz1TUmFk4w"
      },
      "source": [
        "## ステップ2: 参照音声のアップロード（オプション）\n",
        "\n",
        "このステップは**オプション**です。参照音声をアップロードすると、その声質を学習してクローンすることができます。\n",
        "\n",
        "### 参照音声の要件\n",
        "- **長さ**: 10秒〜30秒\n",
        "- **形式**: MP3など（自動的に処理されます）\n",
        "- **品質**: クリアで雑音の少ない音声を推奨\n",
        "\n",
        "スキップする場合は、デフォルトの声が使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install yt-dlp"
      ],
      "metadata": {
        "id": "k2IpmANeFnKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def _time_to_seconds(t):\n",
        "    \"\"\" 秒 or 'MM:SS' or 'HH:MM:SS' を秒に変換 \"\"\"\n",
        "    if t is None:\n",
        "        return None\n",
        "    if isinstance(t, (int, float)):\n",
        "        return int(t)\n",
        "    parts = [int(p) for p in str(t).split(\":\")]\n",
        "    if len(parts) == 1:\n",
        "        return parts[0]\n",
        "    elif len(parts) == 2:\n",
        "        return parts[0] * 60 + parts[1]\n",
        "    elif len(parts) == 3:\n",
        "        return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
        "    else:\n",
        "        raise ValueError(\"時間形式が不正: 秒 or MM:SS or HH:MM:SS を使ってください\")\n",
        "\n",
        "def _get_audio_length(filename):\n",
        "    \"\"\" ffprobe で音声長（秒）を取得 \"\"\"\n",
        "    cmd = [\n",
        "        \"ffprobe\", \"-v\", \"quiet\",\n",
        "        \"-print_format\", \"json\",\n",
        "        \"-show_format\", filename\n",
        "    ]\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    info = json.loads(result.stdout)\n",
        "    return float(info[\"format\"][\"duration\"])\n",
        "\n",
        "def download_youtube_audio_segment(\n",
        "    url: str,\n",
        "    start=None,\n",
        "    end=None,\n",
        "    out_name: str = None,\n",
        "    out_dir: str = \"/content/drive/MyDrive/voice\"\n",
        "):\n",
        "    \"\"\"\n",
        "    start/end 未指定ならフル尺を保存するバージョン\n",
        "    \"\"\"\n",
        "\n",
        "    # 保存先ディレクトリ\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # YouTube 音声ダウンロード\n",
        "    print(\"Downloading audio from YouTube...\")\n",
        "    tmp_tmpl = \"temp_audio.%(ext)s\"\n",
        "    cmd_yt = [\n",
        "        \"yt-dlp\",\n",
        "        \"-f\", \"bestaudio\",\n",
        "        \"--extract-audio\",\n",
        "        \"--audio-format\", \"mp3\",\n",
        "        \"-o\", tmp_tmpl,\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(cmd_yt, check=True)\n",
        "\n",
        "    # temp_audio.xxx を取得\n",
        "    candidate_files = glob.glob(\"temp_audio.*\")\n",
        "    if not candidate_files:\n",
        "        raise FileNotFoundError(\"音声のダウンロードに失敗しました\")\n",
        "    downloaded = candidate_files[0]\n",
        "\n",
        "    # フル尺の場合の処理\n",
        "    length = _get_audio_length(downloaded)\n",
        "\n",
        "    start_s = _time_to_seconds(start)\n",
        "    end_s = _time_to_seconds(end)\n",
        "\n",
        "    if start_s is None:\n",
        "        start_s = 0\n",
        "    if end_s is None:\n",
        "        end_s = int(length)\n",
        "\n",
        "    duration = end_s - start_s\n",
        "    if duration <= 0:\n",
        "        raise ValueError(\"end は start より後にしてください\")\n",
        "\n",
        "    # 出力ファイル名\n",
        "    if out_name is None:\n",
        "        out_name = f\"clip_{start_s}_{end_s}.mp3\"\n",
        "    out_path = os.path.join(out_dir, out_name)\n",
        "\n",
        "    # 指定区間を切り出し\n",
        "    print(\"Extracting segment with ffmpeg...\")\n",
        "    cmd_ff = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-i\", downloaded,\n",
        "        \"-ss\", str(start_s),\n",
        "        \"-t\", str(duration),\n",
        "        out_path\n",
        "    ]\n",
        "    subprocess.run(cmd_ff, check=True)\n",
        "\n",
        "    print(\"Saved:\", out_path)\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "sq0ahQSFG0AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_youtube_audio_segment(\n",
        "    url=\"https://youtu.be/YEJkMKyLS0o?si=-ySHZRZznpha9qDN\"\n",
        ")"
      ],
      "metadata": {
        "id": "XmHf6eHpG1KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44GQDXNGFk4w"
      },
      "outputs": [],
      "source": [
        "# --- 参照音声のアップロードと処理 ---\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import os\n",
        "\n",
        "# 環境変数を設定（UTF-8エンコーディング）\n",
        "os.environ[\"LC_ALL\"] = \"C.UTF-8\"\n",
        "os.environ[\"LANG\"] = \"C.UTF-8\"\n",
        "\n",
        "# --- 参照音声の読み込み ---\n",
        "print(\"参照音声を読み込み中...\")\n",
        "# 音声ファイルを読み込む（wavとサンプリングレートを取得）\n",
        "wav, sampling_rate = torchaudio.load(\"/content/drive/MyDrive/voice/clip_0_42.mp3\")\n",
        "\n",
        "# モデルで音声埋め込みベクトルを作成（声の特徴を抽出）\n",
        "speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
        "print(\"参照音声の読み込みが完了しました！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDCijS1ZFk4w"
      },
      "source": [
        "## ステップ3: テキスト入力と感情設定\n",
        "\n",
        "ここでメインの音声合成を実行します。様々なパラメータを調整できます。\n",
        "\n",
        "### 調整可能なパラメータ\n",
        "\n",
        "1. **text**: 読み上げたいテキスト（日本語にも対応）\n",
        "2. **seed**: ランダムシード（同じ値で同じ結果を再現可能）\n",
        "3. **use_default_speaker**: デフォルトの声を使うか（参照音声を使わない場合はTrue）\n",
        "4. **language**: 言語設定（日本語は'ja'、英語は'en-us'）\n",
        "\n",
        "#### 感情パラメータ（0.0〜1.0の範囲）\n",
        "- **happy**: 喜び\n",
        "- **sad**: 悲しみ\n",
        "- **disgust**: 嫌悪\n",
        "- **fear**: 恐怖\n",
        "- **surprise**: 驚き\n",
        "- **anger**: 怒り\n",
        "- **neutral**: 中立\n",
        "- **other**: その他\n",
        "\n",
        "**注意**: 感情パラメータの合計は自動的に1.0に正規化されます。\n",
        "\n",
        "#### 音声パラメータ\n",
        "- **pitch**: ピッチ（音の高さ）0〜400\n",
        "- **speed**: 話す速度 0〜40（15が標準）\n",
        "\n",
        "### 実行方法\n",
        "1. パラメータを調整\n",
        "2. セルを実行\n",
        "3. 音声が生成され、自動的に再生されます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0E6MjFrFk4w"
      },
      "outputs": [],
      "source": [
        "# --- パラメータ設定 ---\n",
        "# 読み上げるテキスト（英語のサンプル文）\n",
        "text = \" I am motivated by the simple yet profound joys of being alive—the taste of a good meal, the laughter of a friend, the beauty of a sunrise, and the endless pursuit of knowledge. Even if everything about me ceases when I die, my actions, words, and ideas can leave ripples in the world, affecting others in ways I may never fully grasp. \" # @param {type:\"string\"}\n",
        "\n",
        "# ランダムシード（同じ値で同じ結果を再現）\n",
        "seed = 421 # @param {\"type\":\"number\"}\n",
        "\n",
        "# デフォルトの声を使用するかどうか\n",
        "use_default_speaker = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# 言語設定（'en-us': 英語, 'ja': 日本語）\n",
        "language = 'en-us' # @param ['af', 'am', 'an', 'ar', 'as', 'az', 'ba', 'bg', 'bn', 'bpy', 'bs', 'ca', 'cmn', 'cs', 'cy', 'da', 'de', 'el', 'en-029', 'en-gb', 'en-gb-scotland', 'en-gb-x-gbclan', 'en-gb-x-gbcwmd', 'en-gb-x-rp', 'en-us', 'eo', 'es', 'es-419', 'et', 'eu', 'fa', 'fa-latn', 'fi', 'fr-be', 'fr-ch', 'fr-fr', 'ga', 'gd', 'gn', 'grc', 'gu', 'hak', 'hi', 'hr', 'ht', 'hu', 'hy', 'hyw', 'ia', 'id', 'is', 'it', 'ja', 'jbo', 'ka', 'kk', 'kl', 'kn', 'ko', 'kok', 'ku', 'ky', 'la', 'lfn', 'lt', 'lv', 'mi', 'mk', 'ml', 'mr', 'ms', 'mt', 'my', 'nb', 'nci', 'ne', 'nl', 'om', 'or', 'pa', 'pap', 'pl', 'pt', 'pt-br', 'py', 'quc', 'ro', 'ru', 'ru-lv', 'sd', 'shn', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'tn', 'tr', 'tt', 'ur', 'uz', 'vi', 'vi-vn-x-central', 'vi-vn-x-south', 'yue']\n",
        "\n",
        "# --- 感情パラメータ（0.0〜1.0の範囲） ---\n",
        "happy = 0.3077 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 喜び\n",
        "sad = 0.0256 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 悲しみ\n",
        "disgust = 0.0256 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 嫌悪\n",
        "fear = 0.0256 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 恐怖\n",
        "surprise = 0.0256 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 驚き\n",
        "anger = 0.0256 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 怒り\n",
        "other = 0.2564 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # その他\n",
        "neutral = 0.3077 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05} # 中立\n",
        "\n",
        "# --- 音声パラメータ ---\n",
        "pitch = 20 # @param {type:\"slider\", min:0, max:400, step:1} # ピッチ（音の高さ）\n",
        "speed = 15 # @param {type:\"slider\", min:0.0, max:40.0, step:1.0} # 話す速度\n",
        "\n",
        "# --- 感情パラメータの正規化 ---\n",
        "# 全ての感情値の合計を計算\n",
        "total = happy + sad + disgust + fear + surprise + anger + other + neutral\n",
        "if total > 0:\n",
        "    # 合計が1.0になるように正規化\n",
        "    happy = happy / total\n",
        "    sad = sad / total\n",
        "    disgust = disgust / total\n",
        "    fear = fear / total\n",
        "    surprise = surprise / total\n",
        "    anger = anger / total\n",
        "    other = other / total\n",
        "    neutral = neutral / total\n",
        "\n",
        "# 感情値をテンソルに変換\n",
        "emotions = torch.tensor(list(map(float, [happy, sad, disgust, fear, surprise, anger, other, neutral])), device=device)\n",
        "\n",
        "# --- デフォルトの声を使用する場合 ---\n",
        "if use_default_speaker:\n",
        "    print(\"デフォルトの音声を読み込み中...\")\n",
        "    # デフォルトの音声ファイルを読み込む\n",
        "    wav, sampling_rate = torchaudio.load(\"assets/exampleaudio.mp3\")\n",
        "    # 音声埋め込みベクトルを作成\n",
        "    speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
        "    print(\"デフォルトの音声を読み込みました！\")\n",
        "\n",
        "\n",
        "def generate_speech2(text, seed=421, language=\"en-us\", emotion_tensor=torch.tensor(list(map(float, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])), device=device), pitch=20, speed=15):\n",
        "    \"\"\"\n",
        "    テキストから音声を生成する関数\n",
        "\n",
        "    引数:\n",
        "        text: 読み上げるテキスト\n",
        "        seed: ランダムシード\n",
        "        language: 言語コード\n",
        "        emotion_tensor: 感情パラメータのテンソル\n",
        "        pitch: ピッチ（音の高さ）\n",
        "        speed: 話す速度\n",
        "\n",
        "    戻り値:\n",
        "        生成された音声ファイルのパス\n",
        "    \"\"\"\n",
        "    print(f\"音声を生成中: {text}\")\n",
        "\n",
        "    # ランダムシードの設定\n",
        "    if seed >= 0:\n",
        "        torch.manual_seed(seed)  # 再現性のためにシードを固定\n",
        "    else:\n",
        "        torch.random.seed()  # ランダムなシードを使用\n",
        "\n",
        "    # --- 条件付けの作成 ---\n",
        "    # テキスト、言語、声、感情などの条件を辞書にまとめる\n",
        "    cond_dict = make_cond_dict(\n",
        "        text=text,  # 読み上げるテキスト\n",
        "        language=language,  # 言語\n",
        "        speaker=speaker,  # 声の特徴\n",
        "        emotion=emotion_tensor,  # 感情パラメータ\n",
        "        pitch_std=pitch,  # ピッチの標準偏差\n",
        "        speaking_rate=speed  # 話す速度\n",
        "    )\n",
        "    # モデルが理解できる形式に変換\n",
        "    conditioning = model.prepare_conditioning(cond_dict)\n",
        "\n",
        "    # --- 音声の生成 ---\n",
        "    # モデルで音声コードを生成\n",
        "    codes = model.generate(conditioning)\n",
        "    # コードを音声波形にデコード（CPUに転送）\n",
        "    wavs = model.autoencoder.decode(codes).cpu()\n",
        "\n",
        "    # --- 音声の保存 ---\n",
        "    filename = \"output.wav\"\n",
        "    # WAVファイルとして保存\n",
        "    torchaudio.save(filename, wavs[0], model.autoencoder.sampling_rate)\n",
        "    return filename\n",
        "\n",
        "# --- 音声生成の実行 ---\n",
        "output_file = generate_speech2(\n",
        "    text,\n",
        "    seed=seed,\n",
        "    language=language,\n",
        "    emotion_tensor=emotions,\n",
        "    pitch=pitch,\n",
        "    speed=speed\n",
        ")\n",
        "\n",
        "# --- 音声の再生 ---\n",
        "from IPython.display import Audio\n",
        "# Jupyter Notebookで音声を再生\n",
        "Audio(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffCG3zDiI6UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}